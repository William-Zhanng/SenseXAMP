# SenseXAMP

<a href="https://pytorch.org/get-started/locally/"><img alt="PyTorch" src="https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white"></a>

## Supported Tasks
* **Task1**: AMPs Binary classification.
* **Task2**: AMPs regression.
* **Other task**: Such as AMPs ranking and Multilabel classification, will be published in subsequent papers, coming soon.

## Installation

```bash
# clone project
git clone https://github.com/William-Zhanng/SenseXAMP.git
cd SenseXAMP

# create conda virtual environment
conda create -n torch1.7 python=3.8 
conda activate torch1.7

# install all requirements
pip install -r requirements.txt
```

Quick Usage of SenseXAMP
---
## 1. Prepare datasets before using SenseXAMP
### Datasets introduction
Before utilizing SenseXAMP, it's important to prepare the datasets appropriately. Our research utilized several dataset versions, and it's crucial to have **all the following versions** of datasets ready before running SenseXAMP:

#### ori_datasets
- Format: **.csv**
- Description: This includes `train.csv`, `val.csv`, and `test.csv`. These datasets exclusively contain sequences and corresponding labels.
- Obtaining Method: Download the "ori_datasets" version of the datasets from [here.](https://drive.google.com/drive/folders/1L0OKKq3yQmKQTyFSQ3YUmB5RRnba10w1?usp=sharing)
  
#### esm_embeddings
- Format: **.h5**
- Description: These datasets are in .h5 format and are generated using the esm-1b model. This version of the dataset is derived from the `ori_datasets`.
- Obtaining Method: By running the script `tools/esm_emb_gen.py` (Since embeddings files are too large)

#### stc_info
- Format: **.h5**
- Description: These datasets are in .h5 format and are obtained by calculating protein descriptors based on the sequences. This version of the dataset is derived from the `ori_datasets`.
- Obtaining Method: 
  1. Download from  [here.](https://drive.google.com/drive/folders/1L0OKKq3yQmKQTyFSQ3YUmB5RRnba10w1?usp=sharing)
  2. By running the script  `tools/stc_gen.py` (Must get `stc_csv` version first)
  
#### stc_datasets 
- Format: **.csv**
- Description: These datasets are in .h5 format and are obtained by calculating protein descriptors based on the sequences.  Also includes `train.csv`, `val.csv`, and `test.csv`. This version of the dataset is derived from the `ori_datasets`.
- Obtaining Method: By running the script: `tools/generate_csv.py`
  
**Note:** The "stc_csv" dataset version is primarily intended for comparative methods like SMEP and is not necessary for using SenseXAMP.

### Datasets obtain
1. Download the "ori_datasets" version of the datasets from [here.](https://drive.google.com/drive/folders/1L0OKKq3yQmKQTyFSQ3YUmB5RRnba10w1?usp=sharing)

2. Download the "stc_info" version of the datasets from [here.](https://drive.google.com/drive/folders/1gf8uaCBSZjK-R15x6LkGKFSQ4pWI6uUL?usp=sharing)
   
3. For the "esm_embeddings" version of the dataset, it needs to be generated by running `tools/esm_emb_gen.py`.

## 2. Download our model checkpoints to quickly reproduce our results
Download our model checkpoints from [here.](https://drive.google.com/drive/folders/1wNuoFrFZd3q3AlGyV-s2WpaVMs06N4L1?usp=sharing)

## 3. Generate esm-1b embeddings using our scripts.
It is recommended to refer to the project structure we provide to place all versions of datasets.

Here is an example for generating esm-1b embeddings for the `ori_datasets` version of AMPlify dataset.

```bash
python tools/esm_emb_gen.py --dataset_dir ./datasets/ori_datasets/AMPlify --fname AMPlify.h5
```
After running this command, an `AMPlify.h5` file will be generated in the `datasets/esm_embeddings/all` directory.

## 4. Run SenseXAMP
In this project, the model, dataset, and hyperparameters are all setted in `config.py`. Therefore, before running `run.py`, please ensure that the corresponding `config.py` is correctly configured.

### Evaluate with SenseXAMP on the test set.
To be continue
### Train SenseXAMP
To be continue


## Project structure
The core project framework of SenseXAMP is outlined below.  It is recommended to refer to this project structure when organizing all files.
```bash
SenseXAMP/
├── Ampmm_base/  : Core implementaion of trainer, including models, loss, dataloader, etc.
│   ├── data/
│   ├── models/
│   ├── runner/
│   └── utils/
├── configs/     :  This folder contains various configs for different experiments, you can also write your own configs.
│   ├── cls_task/
│   │   ├── benchmark_imblanced_SenseXAMP.py
│   │   ├── benchmark_blanced_SenseXAMP.py
│   │   ├── ...
│   │   └── Your_own_config.py
│   └── reg_task/
│   │   ├── ecoli_SenseXAMP.py
│   │   ├── saureus_SenseXAMP.py
│   │   ├── ...
│   │   └── Your_own_config.py
├── datasets/     :  This folder contains different version of datasets
│   ├── ori_datasets/ : 'ori_datasets' version
│   │   ├── cls_benchmark_imbalanced/
│   │   ├── cls_benchmark_balanced/
│   │   ├── ...
│   │   └── AMPlify/
│   ├── stc_datasets/   : 'stc_datasets' version, same structure as 'ori_datasets'
│   ├── esm_embeddings/ : 'esm_embeddings' version
│   ├── stc_info/       : 'stc_info' version
├── experiments/ :  This folder contains experiments results. (including model checkpoints auto saved)
├── tools/       :  This folder contains useful scripts such as  generation of different version of datasets.
├── utils/       :  This folder contains necessary codes for the implementation of Ampmm_base
├── requirements.txt
└── run.py 
