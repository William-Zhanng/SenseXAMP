# SenseXAMP

<a href="https://pytorch.org/get-started/locally/"><img alt="PyTorch" src="https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white"></a>

## Supported Tasks
* **Task1**: AMPs Binary classification.
* **Task2**: AMPs regression.
* **Other task**: Such as AMPs ranking and Multilabel classification, will be published in subsequent papers, coming soon.

## Installation

```bash
# clone project
git clone https://github.com/William-Zhanng/SenseXAMP.git
cd SenseXAMP

# create conda virtual environment
conda create -n torch1.7 python=3.8 
conda activate torch1.7

# install all requirements
pip install -r requirements.txt
```

Quick Usage of SenseXAMP
---
## 1. Prepare datasets before using SenseXAMP
### Datasets introduction
Before utilizing SenseXAMP, it's important to prepare the datasets appropriately. Our research utilized several dataset versions, and it's crucial to have **all the following versions** of datasets ready before running SenseXAMP:

#### ori_datasets
- Format: **.csv**
- Description: This includes `train.csv`, `val.csv`, and `test.csv`. These datasets exclusively contain sequences and corresponding labels.
- Obtaining Method: Download the "ori_datasets" version of the datasets from [here.](https://drive.google.com/drive/folders/1L0OKKq3yQmKQTyFSQ3YUmB5RRnba10w1?usp=sharing)
  
#### esm_embeddings
- Format: **.h5**
- Description: These datasets are in .h5 format and are generated using the esm-1b model. This version of the dataset is derived from the `ori_datasets`.
- Obtaining Method: By running the script `tools/esm_emb_gen.py` (Since embeddings files are too large)

#### stc_info
- Format: **.h5**
- Description: These datasets are in .h5 format and are obtained by calculating protein descriptors based on the sequences. This version of the dataset is derived from the `ori_datasets`.
- Obtaining Method: 
  1. Download from  [here.](https://drive.google.com/drive/folders/1L0OKKq3yQmKQTyFSQ3YUmB5RRnba10w1?usp=sharing)
  2. By running the script  `tools/stc_gen.py` (Must get `stc_csv` version first)
  
#### stc_csv 
- Format: **.csv**
- Description: These datasets are in .h5 format and are obtained by calculating protein descriptors based on the sequences. This version of the dataset is derived from the `ori_datasets`.
- Obtaining Method: By running the script: `tools/generate_csv.py`
  
**Note:** The "stc_csv" dataset version is primarily intended for comparative methods like SMEP and is not necessary for using SenseXAMP.

### Datasets obtain
1. Download the "ori_datasets" version of the datasets from [here.](https://drive.google.com/drive/folders/1L0OKKq3yQmKQTyFSQ3YUmB5RRnba10w1?usp=sharing)

2. Download the "stc_info" version of the datasets from [here.](https://drive.google.com/drive/folders/1gf8uaCBSZjK-R15x6LkGKFSQ4pWI6uUL?usp=sharing)
   
3. For the "esm_embeddings" version of the dataset, it needs to be generated by running `tools/esm_emb_gen.py`.

## 2. Download our model checkpoints to quickly reproduce our results
Download our model checkpoints from [here.](https://drive.google.com/drive/folders/1wNuoFrFZd3q3AlGyV-s2WpaVMs06N4L1?usp=sharing)

## 3. Generate esm-1b embeddings using our scripts.
Here is an example for generating esm-1b embeddings for the `ori_datasets` version of AMPlify dataset.

```bash
python tools/esm_emb_gen.py --dataset_dir ./datasets/ori_datasets/AMPlify --fname AMPlify.h5
```
After running this command, an `AMPlify.h5` file will be generated in the `datasets/esm_embeddings/all` directory.

<!-- ## Project structure
### Overview of project structure
- SenseXAMP
  - **Ampmm_base**
    - data
    - models
    - runner
    - utils
  - **configs**
  - **datasets**
  - **tools**
    - cd_hit
    - esm_project
    - strcture_data_generation
    - xxx.py
  - **utils**
    - xxx.py
  - **experiments**
  - **train.py**: 

### 1. Ampmm_base
The implementation of the core class, "Trainer," in our code repository.

### 2. configs
**configs**

- cls_task
  - xxx.py
- reg_task
  - xxx.py
  
This directory stores various configuration files that play a crucial role in managing our codebase. It encompasses model parameters, dataset settings, and hyperparameter configurations, all conveniently organized within config files. 

The naming convention for these config files adheres to the following structure: `datasetname_modelname.py`. For instance, the file `benchmark_imbalanced_fusion.py` signifies the SenseXAMP model's application on our classification imbalanced dataset.

### 3. datasets
This directory serves as a repository for various forms of datasets.
- **datasets**
  - ori_datasets
  - stc_datasets
  - stc_info
  - esm_embeddings -->


## 4. Run SenseXAMP
In this project, the model, dataset, and hyperparameters are all setted in `config.py`. Therefore, before running `run.py`, please ensure that the corresponding `config.py` is correctly configured.

### Evaluate with SenseXAMP on the test set.
To be continue
### Train SenseXAMP
To be continue




